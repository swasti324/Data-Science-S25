---
title: "The Islands, Part 1: Design"
author: "Swasti Jain"
date: 2025-4-2
output:
  github_document:
    toc: true
prerequisites:
  - e-stat12-randomization
---

*Purpose*: So far in this class, I've handed you each dataset. But much of the important work of statistics happens *before* data collection. Issues with data collection generally can't be fixed by fancy analysis after the fact. Therefore, in this *two part* challenge, you will first *plan* and then *execute* a statistical project.

To do this, we'll make use of The Islands, an extremely detailed simulation of a virtual population, developed by researchers at the University of Queensland. This is a fascinating sandbox that helps illustrate the difficulties and complexities of collecting real data, while still being more tractable than collecting data from real humans.

This is part 1 of 2. In this part you will *plan* your statistical project, particularly your data collection. Sound data collection is called *statistical design*.

<!-- include-rubric -->

# Grading Rubric

<!-- -------------------------------------------------- -->

Unlike exercises, **challenges will be graded**. The following rubrics define how you will be graded, both on an individual and team basis.

## Individual

<!-- ------------------------- -->

| Category | Needs Improvement | Satisfactory |
|----|----|----|
| Effort | Some task **q**'s left unattempted | All task **q**'s attempted |
| Observed | Did not document observations, or observations incorrect | Documented correct observations based on analysis |
| Supported | Some observations not clearly supported by analysis | All observations clearly supported by analysis (table, graph, etc.) |
| Assessed | Observations include claims not supported by the data, or reflect a level of certainty not warranted by the data | Observations are appropriately qualified by the quality & relevance of the data and (in)conclusiveness of the support |
| Specified | Uses the phrase "more data are necessary" without clarification | Any statement that "more data are necessary" specifies which *specific* data are needed to answer what *specific* question |
| Code Styled | Violations of the [style guide](https://style.tidyverse.org/) hinder readability | Code sufficiently close to the [style guide](https://style.tidyverse.org/) |

## Submission

<!-- ------------------------- -->

Make sure to commit both the challenge report (`report.md` file) and supporting files (`report_files/` folder) when you are done! Then submit a link to Canvas. **Your Challenge submission is not complete without all files uploaded to GitHub.**

# Setup

<!-- ----------------------------------------------------------------------- -->

```{r setup}
library(tidyverse)
library(rsample)

filename_random <- "./data/helvig-random.csv"
```

### **q1** Orientation

Log into [The Islands](https://islands.smp.uq.edu.au/index.php) and head to the [Visitor Center](https://islands.smp.uq.edu.au/visitors.php) on Providence island (to the east). Watch the first three videos on the `Guides` tab.

*Note:* There is no deliverable for this task. BUT, you'll need to be oriented to The Islands in order to do *any* of the tasks below.

The Islands is an *incredibly* detailed simulation of a real population. Islanders are born, die, and move around. The Islands was designed as a teaching tool to help students learn how to apply statistics to collecting data in the real world.

### **q2** Occupied homes

Find the total number of homes in Helvig, and count the number of unoccupied homes. Answer the questions below.

NB. When Zach counted the homes (on 2025-01-08), he found 20 unoccupied out of 536 total. That means the occupied percentage was about 96%. But you still need to count, because your numbers *will* be different!

**Observations**:

-   What is the total number of homes in Helvig?
    -   There are 538 homes in Helvig
-   What is the number of unoccupied homes? (*Hint*: This is not given anywhere. You will have to count them!)
    -   There are 16 unoccupied homes
-   What percent of homes are *occupied*?
    -   97% homes are occupied
-   Are there any sources of *real* uncertainty in the percent occupied you calculated?
    -   Perhaps one house just became occupied moments before I started counting.
-   Are there any sources of *erroneous* uncertainty in the percent occupied you calculated?
    -   My skill in counting can contribute to the erroneous uncertainty

Zach looked at the first 25 homes in Helvig and recorded the `age` and `name` of every person in those homes. These people are provided in `helvig-seq.csv`.

```{r}
## NOTE: Do not edit this
df_sample_seq <- read_csv("./data/helvig-seq.csv")
df_sample_seq
```

You'll use this dataset as a starting point to figure out prevalent *last names* in Helvig.

### **q3** Find common names: Sequential sample

Complete the code below to find the prevalence of the most common *last name* in Helvig using the sample `df_sample_seq`. Answer the questions below.

Make sure to include in `df_q3` the counts as a column named `n`, and the prevalence (number of occurrence divided by total people) as a column `p`. Also, make sure to sort the data in *descending* order of prevalence.

*Hint*: You will have to use what you've learned about string handling to extract the *last names* only!

```{r q3-task}
## TASK: Compute the prevalence and sort
df_q3 <-
  df_sample_seq %>%
  ## TODO: Complete this code
  mutate(last_name = str_extract(name, "[^\\s]+$")) %>%
  count(last_name, name = "n") %>%
  mutate(p = n / sum(n)) %>%
  arrange(desc(p))

df_q3
```

Use the following to check your work.

```{r q3-tests}
## NOTE: No need to change this
## Check that data has `p` column and is in descending order
assertthat::assert_that(
  all(df_q3 %>%
    mutate(d = p - lead(p)) %>%
    filter(!is.na(d)) %>%
    pull(d) >= 0)
)
print("Very good!")
```

*Observations*

-   What last name is most prevalent in `df_sample_seq`?
    -   Sorensen as there are 8 individuals with that last name
-   Is this sample representative of *all* houses in Helvig? Why or why not?
    -   No as it only looks at the first 25 houses in Helvig. It is possible that there are families that live closer together, resulting in a bias for the highest possible last name.

In the exercises, we talked about the importance of random sampling. In the previous challenge, we were able to *simulate* a random sample by running a few lines of code. But in the real world, we have to work harder to gather a random sample. We'll do this in two stages: *plan* then *collect*.

### **q4** Plan a random sample

Complete the code below to draw a sample of size `n=25`. Replace `n_houses` with the (current) total number in Helvig.

```{r}
## TASK: Set the parameters for this code block

## Select a random sample of houses
n_houses <- 538 # Total number of houses
n_sample <- 25 # Desired sample size

set.seed(101) # Set a seed for reproducibility

df_numbers_random <-
  tibble(
    house = sample(
      1:n_houses, # All integers from 1 to n_houses
      n_sample, # Size of our sample
      replace = FALSE # Sample *WITHOUT* replacement
    )
  ) %>%
  # Arrange for our data collection convenience
  arrange(house)

# Pull the column so we can list just the house numbers
df_numbers_random %>%
  pull(house)
```

Use the following code to check your results.

```{r}
## NOTE: No need to change this
assertthat::assert_that(
  all(dim(df_numbers_random) == c(25, 1))
)
```

### **q5** Collect the random sample

Gather the names of all people in the homes you listed in the previous exercise. Match the same columns as `df_sample_seq`; those are, `house`, `age`, `name`. Make sure to include `NA` rows for houses with no occupants. Save your data as a CSV with the filename provided in the variable `filename_random`. Answer the questions below.

```{r}
## NOTE: Do not edit
filename_random
```

Note that this points to the `data/` subdirectory in your `challenges` folder.

The following code will load your data.

```{r}
## NOTE: Do not edit
df_sample_random <-
  read_csv(filename_random)
```

```{r}
# I messed up the original count so my randomization was too large. I picked a different random house that was in bounds
df_numbers_random <- df_numbers_random %>%
  mutate(house = replace(house, n(), 533))
```

Use the following to check your work.

```{r q3-test}
## NOTE: No need to change this
# Check that the dataset has the correct column names
assertthat::assert_that(setequal(
  df_sample_random %>% names(),
  df_sample_seq %>% names()
))

# Check that all of the house numbers in the dataset match those that were planned
numVsamp <-
  anti_join(
    df_numbers_random,
    df_sample_random %>% distinct(house),
    by = "house"
  ) %>%
  pull(house)
assertthat::assert_that(
  length(numVsamp) == 0,
  msg = str_c("You are missing the houses: ", numVsamp)
)

sampVnum <-
  anti_join(
    df_sample_random %>% distinct(house),
    df_numbers_random,
    by = "house"
  ) %>%
  pull(house)
assertthat::assert_that(
  length(sampVnum) == 0,
  msg = str_c("You have extra houses: ", sampVnum)
)

print("Great work!")
```

*Observations*

-   Which sample---sequential or random---is more *representative* of all homes Helvig? Why?
    -   (Sequential or random?)
    -   (Write your 'why' here.)
    -   The random sampling is more representative of all homes in Helvig. I noticed in my random sampling there was a small batch of houses in the same address area that all only had 1 or 2 occupants rather than larger families. Now there isn't enough information stating that there's a specific neighborhood that attracts singles or couples but perhaps there's something to be said about distance from the nearest school or park and the number of families living near it.

### **q6** Find common names: Random sample

Run the code below to find the prevalence of the most common *last name* in Helvig using the sample `df_sample_random`. Answer the questions below.

```{r}
# NOTE: No need to edit; run and answer the questions below
df_sample_random %>%
  mutate(last = str_extract(name, "\\w+$")) %>%
  count(last) %>%
  arrange(desc(n)) %>%
  mutate(p = n / sum(n))
```

*Observations*

-   Did you find any highly prevalent names using `df_sample_random` that you *didn't* find in q3 (using `df_sample_seq`)? Write them here.
    -   Yes, the more prevalent last name was 'Collins'. It didn't even show up in the original
-   Is there any reason that people with the same last name might tend to *live near each other*?
    -   Yes, a big family with similar last names may live in the same house or in a house near other family.

You should have found some difference between the sequential and random samples. This is because we're only working with a *sample*---a limited number of observations from the entire population. We could go to every single house in Helvig and determine *exactly* how many people of each name there are (that's called a *census*), but the point of statistical inference is that we can make statements about a population using only a sample. What makes statistical inference powerful is that we can determine *how confident* we should be in our results, based on the size of our sample.

To do this, we'll use the bootstrap approach that you saw in the exercise sequence. We'll start by building a helper function.

### **q7** Write a helper function

Complete the code below to write a helper function. Your function will compute the proportion of people in a sample that have a user-specified last name.

```{r}
## TASK: Write a helper function that takes a dataframe with full names
#  (provided in a `name` column), removes any invalid rows, and computes the
#  proportion of individuals with the user-specified `last` name (returned
#  in an `estimate` column).
name_prevalence <- function(df, last = "Collins") {
  df %>%
    filter(!is.na(name)) %>%
    mutate(last_name = word(name, -1)) %>%
    summarise(
      term = "prevalence",
      estimate = mean(last_name == last)
    )
}
```

Use the following code to check your results.

```{r}
## NOTE: No need to change this
# Find the most prevalent name in the data
last_most <-
  df_sample_random %>%
  mutate(last = str_extract(name, "\\w+$")) %>%
  count(last) %>%
  arrange(desc(n)) %>%
  slice(1) %>%
  pull(last)

# Ensure correct columns
assertthat::assert_that(
  setequal(
    tibble(name = c("James")) %>% name_prevalence(., last = "James") %>% names(),
    c("term", "estimate")
  ),
  msg = "Your code should result a dataframe with just two columns: `term` and `estimate`"
)

# Ensure NA handling
assertthat::assert_that(
  !(tibble(name = c(NA_character_, "James")) %>%
    name_prevalence(., last = "James") %>%
    pull(estimate) %>%
    is.na()),
  msg = "Ensure your code properly ignores NA's"
)

# Check for correctness
assertthat::assert_that(
  name_prevalence(df_sample_random, last = last_most) %>% pull(estimate) ==
    mean(str_detect(df_sample_random$name, last_most), na.rm = TRUE),
  msg = "Your code computed the wrong value"
)

print("Nice!")
```

### **q8** Construct a bootstrap confidence interval

Choose a prevalent name that you found in q6. Use bootstrap resampling with your helper function to construct a confidence interval for the prevalence of that name. Answer the questions below.

*Hint*: We learned how to do resampling-based inference in `e-stat09`.

```{r}
# TASK: Complete the code below to compute a bootstrap-based confidence interval
df_interval_bootstrap <-
  df_sample_random %>%
  bootstraps(., times = 1000) %>%
  mutate(
    estimate = map(
      splits,
      function(split_df) {
        ## TODO: Finish this code, using the name_prevalence() helper you implemented
        ## HINT: Remember that you need to use analysis() when operating on split_df
        name_prevalence(analysis(split_df), last = "Collins") # apply your helper function
      }
    )
  ) %>%
  ## NOTE: No need to edit this line; this uses your bootstrap sample to compute
  # a confidence `int`erval using the percentile method
  int_pctl(., estimate)

df_interval_bootstrap
```

**Observations**:

-   What is highest possible prevalence for your chosen name, based on the confidence interval you constructed?
    -   the upper bound is 0.19
-   Note that we used the *random* sample with the bootstrap procedure in this task. Could we use the bootstrap to make a confidence interval using the sequential sample (`df_sample_seq`) that would be representative of all of Helvig? Why or why not?
    -   No
    -   The random sample is more representative of all of Helvig. The sequential sample might have bias (families living in houses near one another), it could lead to a biased confidence interval

### **q9** Discover possible measurements

Click on a single islander (you can do this from one of the houses), and take a look at what info they can provide. Write down three pieces of info that you're particularly interested in; this will inform your quantity of interest for the final task.

*Hint*: The videos from the [Visitor Center](https://islands.smp.uq.edu.au/visitors.php) will be especially helpful for getting some ideas.

-   I love the detail that goes into the timeline of their social relationships. I was shocked there were some people I clicked on who lost a friend in childhood. The level of detail is insane.
-   I like that I can ask the islanders to do something crazy like get their liver size measured via ultrasound
-   Pain tolerance is interesting

### **q10** Planning a study (TEAMWORK)

Challenge 10 will be a team assignment where you plan and execute a statistical study using The Islands. You should meet with your learning team for Challenge 10 to complete the steps below---though everyone is responsible for including the plan in their individual Challenge 08 submission.

#### Population

-   (What population are you going to study?)
    -   All of the Islanders? Only the residents of Helvig? Participants meeting certain criteria (in which case, you need to list *covariates*)?
    -   All the senior citizens of Helvig (65+)

#### Quantity of interest

-   The mean number of bicep curls from a senior citizen

#### Covariates

-   Age
-   Gender
-   Physical Activity
-   Health status

#### Observation or experiment?

The Islands allows you to ask islanders to complete tasks. If you just take measurements on your participants, then it's an *observational study*. But if you also introduce something that's meant to change the outcome of a measurement (e.g., drinking coffee before taking a test), that's called an *experimental study*. You need to decide whether your study is observational or experimental.

-   Simply observational study

#### Question / Hypothesis

-   (Write your question / hypothesis here)
    -   This could be an observational question, like "How are X and Y related in the population?"
    -   This could be an experimental question, like "What effect does X have on Y in the population?"
    -   How are age and physical strength related in senior citizens?

#### Sampling plan

-   (What steps will you take to collect the data?)
-   Be specific. For instance, if you're going to collect a random sample, how will you enumerate all of the things to be sampled?
-   Write a protocol. Document step-by-step instructions that your team will follow. That way, you can feasibly split up data collection among the whole team, while making sure each team member doesn't make ad hoc decisions that introduce bias into your results.

<!-- -->

-   (How will you ensure the data is representative of your chosen population?)

-   (For experiments only: How will you ensure any effects you observe are due to the treatment, and not due to other factors?)

-   (How will you choose your sample size?)

    -   This should be a mix of how confident you want to be in your results, and what is actually *feasible* for your research team.

    -   I am going to collect a random sample of senior citizens.

    -   According to the bureau there are 113 total senior citizens. I will randomize houses until I reach 23 participants (\~20%) that meet the criteria of being 65 or over. This will help create a representative sample

    -   Choosing 20% of the total available population will provide a good balance between reflecting diversity as well as manageable for the team

    -   I will only choose 1 participant from each house to not allow any bias from similar lifestyles.
